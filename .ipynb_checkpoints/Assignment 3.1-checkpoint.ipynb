{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aebf4917",
   "metadata": {},
   "source": [
    "# Assignment 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f2f8a1",
   "metadata": {},
   "source": [
    "# House Price Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57bfcd3",
   "metadata": {},
   "source": [
    "In this assignment,  we will focus on learning some best practices on the typical PyData libraries: Jupyter/IPython, Pandas, Numpy, Scikit-learn, Matplotlib."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb20553",
   "metadata": {},
   "source": [
    "Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "992d452d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import tarfile\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03d45267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Source Location\n",
    "\n",
    "DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81720c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "    os.makedirs(housing_path, exist_ok=True)\n",
    "    tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "    urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "    housing_tgz = tarfile.open(tgz_path)\n",
    "    housing_tgz.extractall(path=housing_path)\n",
    "    housing_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac265824",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f64ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_housing_data(housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ba68a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing=load_housing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa763f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the first 10 rows of the data\n",
    "\n",
    "housing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15c6e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the data set\n",
    "housing.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7742cc",
   "metadata": {},
   "source": [
    "let's check the statistical description of the attributes within the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10e8f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0385c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8de75a2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e080c38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f60edd",
   "metadata": {},
   "source": [
    "Let's Visualize our data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49ed41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "housing.hist(bins=50, figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bafe85c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Split the data into Train and Test Set.\n",
    "\n",
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39137c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set, test_set =split_train_test(housing, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "203c054d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Length of Train Set\", len(train_set))\n",
    "print(\"Length of Test Set\", len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "028c0e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from zlib import crc32\n",
    "\n",
    "def test_set_check(identifier, test_ratio):\n",
    "    return crc32(np.int64(identifier)) & 0xffffffff < test_ratio * 2**32\n",
    "\n",
    "def split_train_test_by_id(data, test_ratio, id_column):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e61dd06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_with_id = housing.reset_index()   # adds an `index` column\n",
    "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba1616b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_with_id[\"id\"] = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\n",
    "train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a319094b",
   "metadata": {},
   "source": [
    "let's have a look on train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67bef0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train set\n",
    "train_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40b1a73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Set\n",
    "test_set.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8e27da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "02366ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "393d5b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25200660",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],\n",
    "                               labels=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "205492d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"].hist(figsize=(5,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43ec246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ee5de88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5545b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_test_set[\"income_cat\"].value_counts() / len(strat_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d8fb5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"].value_counts()/len(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e1d8c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def income_category_proportions(data):\n",
    "    return data[\"income_cat\"].value_counts() / len(data)\n",
    "\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "\n",
    "compare_proportions = pd.DataFrame({\n",
    "    \"Overall_Proportion\": income_category_proportions(housing),\n",
    "    \"Stratified_Proportion\": income_category_proportions(strat_test_set),\n",
    "    \"Random_Proportion\": income_category_proportions(test_set),\n",
    "}).sort_index()\n",
    "compare_proportions[\"Random %error\"] = 100 * compare_proportions[\"Random_Proportion\"] / compare_proportions[\"Overall_Proportion\"] - 100\n",
    "compare_proportions[\"Stratified %error\"] = 100 * compare_proportions[\"Stratified_Proportion\"] / compare_proportions[\"Overall_Proportion\"] - 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04ac2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44b870e",
   "metadata": {},
   "source": [
    "Now we will remove the income_cat attribute so the data is back to its original state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6d291417",
   "metadata": {},
   "outputs": [],
   "source": [
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"income_cat\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80e88d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "strat_train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00104ed",
   "metadata": {},
   "source": [
    "# Let's Visualize the data and discover few insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "800d9265",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing=strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9535c8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "48b83f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b995c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"longitude\", y=\"latitude\", alpha=0.4,\n",
    "    s=housing[\"population\"]/100, label=\"population\", figsize=(10,7),\n",
    "    c=\"median_house_value\", cmap=plt.get_cmap(\"jet\"), colorbar=True,\n",
    ")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dea50290",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing=housing.drop(\"ocean_proximity\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994333da",
   "metadata": {},
   "source": [
    "check the correlation in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2f17f586",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix=housing.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95ad3b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fe8efac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "attributes = [\"median_house_value\", \"median_income\", \"total_rooms\",\n",
    "              \"housing_median_age\"]\n",
    "scatter_matrix(housing[attributes], figsize=(12, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9fca0953",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.plot(kind=\"scatter\", x=\"median_income\", y=\"median_house_value\",\n",
    "             alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5bb649",
   "metadata": {},
   "source": [
    "# Let's Experiment with Attribute Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1248cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"rooms_per_household\"] = housing[\"total_rooms\"]/housing[\"households\"]\n",
    "housing[\"bedrooms_per_room\"] = housing[\"total_bedrooms\"]/housing[\"total_rooms\"]\n",
    "housing[\"population_per_household\"]=housing[\"population\"]/housing[\"households\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58e6ed0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = housing.corr()\n",
    "corr_matrix[\"median_house_value\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f85e479",
   "metadata": {},
   "source": [
    "# Let's Prepare the Data for Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "021e7fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "housing_labels = strat_train_set[\"median_house_value\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3e10f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "df23dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a81b44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the median can only be computed on numerical value, let's drop the categorical column \"ocean_proxomity\"\n",
    "housing_num = housing.drop(\"ocean_proximity\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd8fcac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.fit(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "151ab2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a61dd48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num.median().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ae8ba42",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = imputer.transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4f0200a",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr = pd.DataFrame(X, columns=housing_num.columns,\n",
    "                          index=housing_num.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "70369a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer.strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "10916c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_tr.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c338ace",
   "metadata": {},
   "source": [
    "# Let's Handle Text and Categorical Attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bb95b886",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat = housing[[\"ocean_proximity\"]]\n",
    "housing_cat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9a8704dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)\n",
    "housing_cat_encoded[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "371bacf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_encoder.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16e2fa08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "cat_encoder = OneHotEncoder()\n",
    "housing_cat_1hot = cat_encoder.fit_transform(housing_cat)\n",
    "housing_cat_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0083151b",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d778018f",
   "metadata": {},
   "source": [
    "Notice that OneHotEncoding returns sparse matrix instead of NumPy array. Sparse Matrix is full of 0's except for a single 1 per row.\n",
    "We need to call toarray() method to convert it into Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "843f8ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_cat_1hot.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d0f3b77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_encoder.categories_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d4ad77",
   "metadata": {},
   "source": [
    "# Custom Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f473c903",
   "metadata": {},
   "source": [
    "To easily find out whether adding this attribute helps the Machine Learning algorithms or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a549fc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "\n",
    "class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "        self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "    def fit(self, X, y=None):\n",
    "        return self  # nothing else to do\n",
    "    def transform(self, X):\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "        if self.add_bedrooms_per_room:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household,\n",
    "                         bedrooms_per_room]\n",
    "\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "housing_extra_attribs = attr_adder.transform(housing.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972d7127",
   "metadata": {},
   "source": [
    "# Transformation Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1b4f2b",
   "metadata": {},
   "source": [
    "let's build the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1e01c713",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "        ('attribs_adder', CombinedAttributesAdder()),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "housing_num_tr = num_pipeline.fit_transform(housing_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ebdc31ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_num_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "60f712f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "num_attribs = list(housing_num)\n",
    "cat_attribs = [\"ocean_proximity\"]\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "housing_prepared = full_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dfe77a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b0b64c",
   "metadata": {},
   "source": [
    "# Let's Select and Train a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5477f53",
   "metadata": {},
   "source": [
    "# Training and Evaluating on the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "027c733f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0e462511",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = housing.iloc[:5]\n",
    "some_labels = housing_labels.iloc[:5]\n",
    "some_data_prepared = full_pipeline.transform(some_data)\n",
    "\n",
    "print(\"Predictions:\", lin_reg.predict(some_data_prepared))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2d4507",
   "metadata": {},
   "source": [
    "Let's check with the actual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ea3635f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Labels:\", list(some_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b89f9175",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(some_data_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a72644aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2381af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "housing_predictions = lin_reg.predict(housing_prepared)\n",
    "lin_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea648c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "linear_mae = mean_absolute_error(housing_labels, housing_predictions)\n",
    "linear_mae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3083e68",
   "metadata": {},
   "source": [
    "Let's train a Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ea3ef9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474bb6c8",
   "metadata": {},
   "source": [
    "As the model is trained, let's evaluate on Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d1c0c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions = tree_reg.predict(housing_prepared)\n",
    "tree_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ee493e",
   "metadata": {},
   "source": [
    "it is much more likely that the model has badly overfit the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d36112",
   "metadata": {},
   "source": [
    "# Better Evaluation Using Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d833ffa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, housing_prepared, housing_labels,\n",
    "                         scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ec1f7b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "display_scores(tree_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6d8e1b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "lin_scores = cross_val_score(lin_reg, housing_prepared, housing_labels,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485c5edc",
   "metadata": {},
   "source": [
    "That’s right: the Decision Tree model is overfitting so badly that it performs worse than the Linear Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "774266e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "forest_reg.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3c57b9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_predictions = forest_reg.predict(housing_prepared)\n",
    "forest_mse = mean_squared_error(housing_labels, housing_predictions)\n",
    "forest_rmse = np.sqrt(forest_mse)\n",
    "forest_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64a94c8",
   "metadata": {},
   "source": [
    "# Let's fine tune our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1e800c",
   "metadata": {},
   "source": [
    "Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4c072711",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # tryfirst 12 (3×4) combinations of hyperparameters\n",
    "    {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "    # then we will try 6 (2×3) combinations with bootstrap set as False\n",
    "    {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "  ]\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "# train across 5 folds i.e. total (12+6)*5=90 rounds of training \n",
    "grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error',\n",
    "                           return_train_score=True)\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "b8682874",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42be7ce6",
   "metadata": {},
   "source": [
    "we can also get the best estimator directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "46a0e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302b983e",
   "metadata": {},
   "source": [
    "Let's have a look on evaluation score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f2d07cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9d6cfaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f615b05c",
   "metadata": {},
   "source": [
    "Now let's perform Randomized Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc07f774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab15bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e092ed",
   "metadata": {},
   "source": [
    "Now Let's Analyze the Best Models and Their Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f13135",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabd9c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3855791",
   "metadata": {},
   "source": [
    "# Now Evaluate the model on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c728e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9042add",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea65c7f",
   "metadata": {},
   "source": [
    "We can compute a 95% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513983ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "confidence = 0.95\n",
    "squared_errors = (final_predictions - y_test) ** 2\n",
    "np.sqrt(stats.t.interval(confidence, len(squared_errors) - 1,\n",
    "                         loc=squared_errors.mean(),\n",
    "                         scale=stats.sem(squared_errors)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4c6bca",
   "metadata": {},
   "source": [
    "Full Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b0d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline_with_predictor = Pipeline([\n",
    "        (\"preparation\", full_pipeline),\n",
    "        (\"linear\", LinearRegression())\n",
    "    ])\n",
    "\n",
    "full_pipeline_with_predictor.fit(housing, housing_labels)\n",
    "full_pipeline_with_predictor.predict(some_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58c1118",
   "metadata": {},
   "source": [
    "Let's Persist the model using joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2267a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = full_pipeline_with_predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205cf66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(my_model, \"my_model.pkl\")\n",
    "my_model_loaded = joblib.load(\"my_model.pkl\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043dbd9d",
   "metadata": {},
   "source": [
    "======================================================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e03ddf2",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde7f2fc",
   "metadata": {},
   "source": [
    "Question 1:\n",
    "Try a Support Vector Machine regressor (sklearn.svm.SVR) with various hyperparameters, such as kernel=\"linear\" (with various values for the C hyperparameter) or kernel=\"rbf\" (with various values for the C and gamma hyperparameters). Don’t worry about what these hyperparameters mean for now. How does the best SVR predictor perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f5e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "param_grid = [\n",
    "        {'kernel': ['linear'], 'C': [10., 30.]},\n",
    "        {'kernel': ['rbf'], 'C': [1.0, 3.0, 10.],\n",
    "         'gamma': [0.01, 0.03, 0.1, 0.3]},\n",
    "    ]\n",
    "\n",
    "svm_reg = SVR()\n",
    "grid_search = GridSearchCV(svm_reg, param_grid, cv=2, scoring='neg_mean_squared_error', verbose=2,n_jobs=1)\n",
    "grid_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379e8223",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_mse = grid_search.best_score_\n",
    "rmse = np.sqrt(-negative_mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6702763e",
   "metadata": {},
   "source": [
    "it is performing worse as compared to RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e194713b",
   "metadata": {},
   "source": [
    "let's check the most optimal hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19ac2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b6d7e7",
   "metadata": {},
   "source": [
    "It is visible from the above that the Linear Kernal performing better as compared to RBF kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c4c416",
   "metadata": {},
   "source": [
    "Question 2:\n",
    "Try replacing GridSearchCV with RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc6c78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import expon, reciprocal\n",
    "\n",
    "param_distribs = {\n",
    "        'kernel': ['linear', 'rbf'],\n",
    "        'C': reciprocal(20, 200),\n",
    "        'gamma': expon(scale=1.0),\n",
    "    }\n",
    "\n",
    "svm_reg = SVR()\n",
    "rnd_search = RandomizedSearchCV(svm_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=3, scoring='neg_mean_squared_error',\n",
    "                                verbose=2, random_state=42)\n",
    "rnd_search.fit(housing_prepared, housing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46105eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_mse = rnd_search.best_score_\n",
    "rmse = np.sqrt(-negative_mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeae4596",
   "metadata": {},
   "source": [
    "let's check the most optimal hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e3f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1780ddf6",
   "metadata": {},
   "source": [
    "The hyperparameter looks good for the RBF Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f24bc1",
   "metadata": {},
   "source": [
    "Let's have a look at the exponential distributioN used, with scale=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adefc4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "expon_distrib = expon(scale=1.)\n",
    "samples = expon_distrib.rvs(10000, random_state=42)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Exponential distribution (scale=1.0)\")\n",
    "plt.hist(samples, bins=50)\n",
    "plt.subplot(122)\n",
    "plt.title(\"Log of this distribution\")\n",
    "plt.hist(np.log(samples), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cb7314",
   "metadata": {},
   "outputs": [],
   "source": [
    "reciprocal_distrib = reciprocal(20, 200000)\n",
    "samples = reciprocal_distrib.rvs(10000, random_state=42)\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Reciprocal distribution (scale=1.0)\")\n",
    "plt.hist(samples, bins=50)\n",
    "plt.subplot(122)\n",
    "plt.title(\"Log of this distribution\")\n",
    "plt.hist(np.log(samples), bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7391a58c",
   "metadata": {},
   "source": [
    "Question 3:\n",
    "Try adding a transformer in the preparation pipeline to select only the most important attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd7cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "def indices_of_top_k(arr, k):\n",
    "    return np.sort(np.argpartition(np.array(arr), -k)[-k:])\n",
    "\n",
    "class TopFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, feature_importances, k):\n",
    "        self.feature_importances = feature_importances\n",
    "        self.k = k\n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_indices_ = indices_of_top_k(self.feature_importances, self.k)\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[:, self.feature_indices_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41069d39",
   "metadata": {},
   "source": [
    "let's assume we want k number of top features and we will conside it 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c47205",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5\n",
    "\n",
    "top_k_feature_indices = indices_of_top_k(feature_importances, k)\n",
    "top_k_feature_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7b37d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(attributes)[top_k_feature_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a8c7de",
   "metadata": {},
   "source": [
    "let's verify and be sure of these are top 5 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1c25d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(feature_importances, attributes), reverse=True)[:k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da29f26",
   "metadata": {},
   "source": [
    "Create a Pipeline that runs previous pipeline and adds top k=5 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ff0fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "preparation_and_feature_selection_pipeline = Pipeline([\n",
    "    ('preparation', full_pipeline),\n",
    "    ('feature_selection', TopFeatureSelector(feature_importances, k))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2210d611",
   "metadata": {},
   "source": [
    "look at first 3 instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c202e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared_top_k_features = preparation_and_feature_selection_pipeline.fit_transform(housing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093fe62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared_top_k_features[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c92b62",
   "metadata": {},
   "source": [
    "let's verify and be sure of these are top k features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaa7159",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_prepared[0:3, top_k_feature_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb2badf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
